# Clustering-approaches-for-mixed-type-data-A-comparative-study
Abstract: Clustering is widely used in unsupervised learning to find homogeneous groups of observations within a dataset. However, clustering mixed-type data remains a challenge, as few existing approaches are suited for this task. This study presents the state-of-the-art of these approaches and compares them using various simulation models. The compared methods include the distance-based approaches k-prototypes, PDQ and Convex k-means, and the probabilistic methods KAMILA, the mixture of Bayesian networks (MBN) and Latent Class Model (LCM). The aim is to provide insights into the behaviour of different methods across a wide range of scenarios by varying some experimental factors such as the number of clusters, cluster overlap, sample size, dimension, proportion of continuous variables in the dataset and clusters' distribution. The degree of cluster overlap and the proportion of continuous variables in the dataset and the sample size have a significant impact on the observed performances. When strong interactions exist between variables alongside an explicit dependence on cluster membership, none of the evaluated methods demonstrated satisfactory performance. In our experiments KAMILA, LCM and k-prototypes exhibited the best performance, with respect to the adjusted rand index (ARI). All the methods are available in R software.
